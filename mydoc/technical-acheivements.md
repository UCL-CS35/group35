---
title: Technical Achievements
last_updated: March 20, 2016
sidebar: mydoc_sidebar
permalink: /development/technical-acheivements/
---

## Implementation Details


### 1. Neurosynth Dataset generation. 
    
INcDb requires a Neurosynth dataset that it uses to generate Term Analyses. The generation of Neurosynth Dataset is a memory-intensive operation which is not suitable to be done on a remote server, which typically has less RAM. 

We suggest the Dataset to be generated on a local machine. Follow the instructions on <https://github.com/neurosynth/neurosynth> to build your own Dataset (`neurosynth_dataset.pkl`) and copy the Dataset to `incdb-poc/app/data/assets/`.

With the Dataset in place, we can initialise the database and add the Analyses to the database. These analyses will then be used to compute the correlation of the Components with the Terms.

### 2. Flask Application
		
The main function of the INcDb is the repository browsing. This is implemented using database query and Flask routing mechanism. Flask routing function help to pass variable name through the URL and this variable is used to select the necessary data from the database to be displayed. 

The user management was implemented using the Flask extension - Flask-User. The user management allow signed in users to create Collection and upload Raw Dataset. 

Flask-WTF, a Flask extension, was used to simplify the creation of the complicated Collection's form. 

### 3. Computation of correlation between Component and Terms
   
Another key function performed by the INcDb is to compute the correlations of the Components uploaded by our client with the Terms Analyses generated by the Neurosynth Dataset generation. As requested by our client, we referenced the computation done by the open-sourced Neurosynth-Web, <https://github.com/neurosynth/neurosynth-web/blob/master/nsweb/tasks/__init__.py>, and implemented a similar decoding function for INcDb.

The decoding is done when new Processed Dataset is uploaded to the server by our client and the top 10 Terms (with the highest correlations) for each Component are stored in a text files on the remote server. These text files are retrieved to display the correlation values when user view the Component.

For each Component of the Processed Dataset, a row in the Decodings table (in the database) is also created and tagged with the Term that it has the higest correlation with.

### 4. Neurosynth Viewer
   
(Explain setup, selection of Components, merging)

### 5. Background task using Celery and Redis

(Explain how is it move to backgound, starting celery workers, running redis server)

## Dependencies

The application is developed with a list of dependecies. The complete list of Python packages dependencies can be found at <https://github.com/UCL-CS35/incdb-poc/blob/master/requirements.txt>.

We will like to highlight a few key dependencies that were critical for the development of INcDb.

<table>
	<thead>
		<tr>
			<th>Name</th>
			<th>Role</th>
		</tr>
	</thead>
	<tbody>
		<tr>
			<td width="15%">Flask</td>
			<td>The micro-framework that INcDb runs on.</td>
		</tr>
		<tr>
			<td>Flask-User</td>
			<td>Flask extension used to implement User Management feature.</td>
		</tr>
		<tr>
			<td>Flask-WTF</td>
			<td>Flask extension used to simply form creation.</td>
		</tr>
		<tr>
			<td>Neurosynth</td>
			<td>Neurosynth is used to generate analyses that is used for the decoding of the Processed Dataset uploaded by our client.</td>
		</tr>
		<tr>
			<td>gunicorn</td>
			<td>A Python WSGI HTTP Server to serve the Flask application.</td>
		</tr>
		<tr>
			<td>celery</td>
			<td>A task processing system used to manage background tasks like decoding.</td>
		</tr>
		<tr>
			<td>Redis</td>
			<td>Redis is used as message broker to pass messages between Flask application and Celery workers.</td>
		</tr>
	</tbody>
</table>

## Code Structure

The application first-level code structure is presented below and the role of each file or folder is explained.

* incdb-poc/
    * app/
        * Contains Models, Views (templates), Controllers, Static files (CSS, JS, Images, Fonts), Setup scripts
    * data/
        * Contains Neurosynth Dataset, Decoding results, Admin uploaded Processed Dataset, Generated memmaps, FAQ data
    * default/
    * docs/
        * Documentations generated by Sphinx
    * migrations/
    		* Migrations genereted (Currently empty)
    * node_modules/
        * Node modules required to run Neurosynth Viewer
    * src/
        * Coffeescript requred to run Neurosnyth Viewer
    * tests/
        * pytests written to test User Managemnent, Search, Creation of Collection
    * uploads/
        * Contains User uploaded Raw Dataset
    * .gitignore
        * Ignore Database and Data folders 
    * Aptfile
    * Cakefile
    * Guardfile
    * LICENSE.txt
    * manage.py
        * Use to start the Flask application
    * README.md
    * requirements.txt
        * List of Python packages required
    * runserver.sh
        * Bash script to run the the Flask application in development mode
    * runtests.sh
        * Bash script to run the Test Cases in /tests folder
    * supervsiord.conf
        * Supervisor configuration file used for Deployment

For the complete code, you can view them on [GitHub](https://github.com/UCL-CS35/incdb-poc). 